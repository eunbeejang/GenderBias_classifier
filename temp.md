Android is an open-source platform developed for mobile devices. It is the most popular operating system that reaches a broader audience as it powers the majority of mobile devices around the world every day [Tutorial, 1.0]. Android provides a one-stop solution to mobile development with a software development kit (SDK) to aid development effort and a marketplace to distribute apps to the public. Moreover, the users can provide reviews and feedback directly to the developers, allowing them to make essential decisions on app improvements, such as resolving issues and designing new features. Thus, the Android ecosystem provides plenty of open data that can easily be crawled, and there are reasonable grounds for software engineering research that can support mobile development tasks.

In recent literature discussed in COMP 599, scholars explore diverse mobile application development topics. Most studies focus on the automation of the tasks that were previously reserved for humans to reduce the manual effort required for development teams. I categorize these issue topics based on the various stages of the software development pipeline, as it is shared knowledge and is most intuitive for both developers and researchers to follow. We can breakdown their categories into four broad topics: ideation, development, maintenance, and security concerns. Each category can stem into subcategories by the order of development life-cycle and/or by the context of issues being addressed. 

#Ideation
“An Android app project begins with an idea and a definition of the requirements necessary to realize that idea” [Tutorial, 1.1]. There may be numerous reasons why developers want to build specific apps. Whatever the interest may be, reviewing existing apps for market research is important. It can help with understanding the need and demand for Android users, design trends, functionalities, and/or the possibility of monetization. This task requires the entire development team “painstaking efforts to review many existing apps with similar purposes” [StoryDroid, p.1]. Individuals in a development team observe different issues and it is crucial to clearly communicate between team members.

One study we have observed relating to this category is <StoryDroid>. Their work involves a tool that generates a storyboard of Android apps, which is an overview of existing similar applications in the market. They approach the problem by extracting activity transitions from Android Package Kit (APK) and statically rendering UI pages. During this process, layout code, activity code and method hierarchy are also analyzed. The strength of their study lies in that they aim to assist multiple development roles, eliciting efficiency and collaborative communication between team members. However, the bottleneck to their approach is in creating the activity transition graph. A failure to render UI pages during static analysis results in an incomplete graph [StoryDroid, p.9] and thus, understanding what type of UI pages elicit such failure is necessary. Moreover, in many cases, the quality of different applications vary and choosing a good set of similar application that satisfies all the team members comes with many challenges. For that reason, a system that can verify application quality would be an interesting future direction.



#Development
The second category relates to the development process of an app. Thus, I call this issue category as Development. After the ideation phase, the development team goes through the following steps: UI/UX designers define the layouts for the app and the developers write the code based on the mock-up of user interface and the various app functions. After the app is built and ran on the devices, the developers go through multiple phases of testing and debugging before officially publishing it on the marketplace.

I define two subcategory issues within Development. One relates to the discrepancy between the intended design and the wrong implementation. Such problems may arise when product managers and UI/UX designers miscommunicate with the code writers on the details of implementations. The verification of each concept is very time-consuming and labour-intensive. <GVT> presents an automated approach to address a subset of this issue, GUI design violations. After creating separate GUI hierarchy graphs for mock-up and actual app implementation, they use the K-nearest neighbour algorithm to detect corresponding GUI components. The scholars then leverage a computer vision technique called perceptual image differencing to identify the visual discrepancy between the implemented work and the design mock-up. As many recent successful studies, <GVT> shows a successful and advanced use of machine learning algorithms to solve software engineering downstream tasks.

Another subcategory involves issues arising due to errors or unexpected behaviour in the code. “Even though you have an app that compiles and runs and looks the way you want it to on different devices, you must make sure that your app will behave the way you expect it to in every situation” [Tutorial, 3.2]. Different devices, Android API versions, and/or App versions may impact the behaviour of the apps and it is necessary to verify the compatibility concerns. Detecting such an issue is ineffective even for humans, and prior research shows that “humans can cover only 30.08% of the app screens and 6.46% of the app methods” [Mimic, p.246-247]. This suggests that it is necessary to have an automated approach that systematically analyzes the compatibility issues. <Mimic> utilizes multiple devices for parallel testing, where the rest of the devices are compared to the ‘leader’ device. They take a similar approach taken by <GVT>, using a screenshot and generating a UI element hierarchy tree. The authors focus on testing “only the important events relevant to UI compatibility” [Mimic, p,248] and, thus, filters out UI elements during runtime analysis. The challenge with this subcategory is that the developers do not have access to the target errors to resolve. The approach taken by <Mimic> is interesting since it mitigates the absence of target by setting a leader device as golden.


#Maintanance
The maintenance category concerns the issues that arise after the app is deployed. Unlike the bugs and errors found during the development process, user reviews or issue reports are available during this step, and they provide direct information about specific problems. In class, we have seen three pieces of literature that fall into Maintanance category: <ChangeAdviser>, <RecDroid>, and <Droix>. These experiments are similar in that they attempt to utilize natural language processing techniques to investigate user reviews and issue reports. <ChangeAdviser> focuses on extracting useful feedback for changes to software artifacts [ChangeAdviser, p.1]. They investigate structure, semantics, and sentiment of natural language to cluster similar user reviews to extract new recommendations. <RecDroid>, on the other hand, aims to reproduce app crashes using natural language bug reports. The authors use NLP techniques to extract GUI keywords and use a pretrained embedding to perform dynamic matching on the generated event tree. Lastly, <Droix> aims to repair crashes and errors automatically. They first analyze crash causes using GitHub issue threads involving natural language and identify eight repair operators (i.e. Try-catch, Null-check, Replace Method) that can be used to resolve crashes in substeps. The availability of natural language tokens provides a chance to leverage transfer learning. However, it is crucial to evaluate the quality of the user entered reviews and issue reports. Writing styles can vary across people, and using a poorly written review entry to extract keywords will impact the results of experiments significantly.


#Security
The last category involves issues with security concerns. They relate to suspicious user data collection and malicious behaviour of applications. In general, “app producers provide policies disclosing what kind of information is collected and processed by the app” [GUILeak, p.1], but data leakage can happen unintentionally. Similarly, malicious applications can intentionally collect user data without informing users. <IconIntent> stresses that many mobile apps collect such data through UI widgets. Thus, they detect suspicious permission requests by categorizing the intent of object and text icons. I personally think their approach to icon identification was naively done. Using OCR to identify text on a very low-resolution image would not result in a good performance. On the other hand, <GUILeak> detects privacy leak by analyzing user-entered data from GUI. It uses a set of semantic relationships to construct an ontology graph. However, manually identifying the hypernym relationship is a challenging task for crowdsource workers. Although the experiment goals for both literatures are interesting, their techniques are limited and can be improved.

The papers that address the malicious behaviour of apps include <FraudDroid> and <LibD>. <FraudDroid> investigates a wide range of ad frauds and presents a taxonomy of fraud. Then the authors dynamically analyze runtime network traffics to build the UI state transition graph. Their work is different in that previous studies mainly focus on the static information such as size and location of ad view. Similarly, <LibD> detects third-party libraries that are pervasively integrated into mobile applications for potential malicious attacks. They use internal code dependencies to cluster library candidates and use hashing to generate features for library identification. Both of these tasks are challenging to address because it is hard to verify whether developers intended to create such security risks or not. A clear guideline that discusses fraudulent and malicious behaviour in Android development would be a valuable study for future work.


#Bonus Question
Android development principles related to security and privacy of user data
Some papers we read in class are related to privacy and security risks for user data collection. However, the android tutorial we’ve used does not cover these sensitive issues. All developers should be aware of such a topic so I think it can be an interesting topic to teach.
