{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Text Classifier\n",
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eunbeejang/anaconda3\n",
      "/usr/local/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.prefix)\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe, Vectors\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "import copy\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "from tqdm import tqdm # progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    tokenize = lambda x: lemma.lemmatize(re.sub(r'<.*?>|[^\\w\\s]|\\d+', '', x)).split()\n",
    "    \n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True,\n",
    "                       include_lengths=True, batch_first=True, dtype=torch.long) #fix_length=200,\n",
    "    LABEL = data.LabelField(batch_first=True, sequential=False)\n",
    "\n",
    "    train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "    \n",
    "    TEXT.build_vocab(train, max_size=25000, vectors=GloVe(name='6B', dim=300)) # Glove Embedding\n",
    "    LABEL.build_vocab(train)\n",
    "    word_emb = TEXT.vocab.vectors\n",
    "    \n",
    "    train, valid = train.split()\n",
    "    train_data, valid_data, test_data = data.BucketIterator.splits((train, valid, test),\n",
    "                                                                   batch_size=64, repeat=False, shuffle=True)\n",
    "\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    print (\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n",
    "    print (\"Vector size of Text Vocabulary: \", TEXT.vocab.vectors.size())\n",
    "    print (\"Label Length: \" + str(len(LABEL.vocab)))\n",
    "    print (\"\\nSize of train set: {} \\nSize of validation set: {} \\nSize of test set: {}\".format(len(train_data.dataset), len(valid_data.dataset), len(test_data.dataset)))\n",
    "    print(LABEL.vocab.freqs.most_common(2))\n",
    "\n",
    "    return TEXT, word_emb, train_data, valid_data, test_data, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Vocabulary: 25002\n",
      "Vector size of Text Vocabulary:  torch.Size([25002, 300])\n",
      "Label Length: 2\n",
      "\n",
      "Size of train set: 17500 \n",
      "Size of validation set: 7500 \n",
      "Size of test set: 25000\n",
      "[('pos', 12500), ('neg', 12500)]\n"
     ]
    }
   ],
   "source": [
    "TEXT, word_emb, train_data, valid_data, test_data, vocab_size = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 994])"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a in train_data:\n",
    "    b = a.text\n",
    "    break\n",
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    16,      2,   2274,    230,     40,     38,     11,     13,\n",
       "            146,      9],\n",
       "        [     2,    231,    116,      4,    169,      5,    432,   1570,\n",
       "             16,      4],\n",
       "        [    33,   6848,  22956,  14019,    251,     32,      4,    176,\n",
       "              3,    805],\n",
       "        [  1250,  22470,    108,   1810,    647,      6,      2,    245,\n",
       "             36,      2],\n",
       "        [   484,    130,     85,    476,   6536,     66,   2762,     14,\n",
       "             32,     10],\n",
       "        [     2,    426,     15,      2,      0,      7,   7548,     55,\n",
       "             32,      2],\n",
       "        [    10,     17,     13,      4,    517,   1096,      9,     13,\n",
       "            196,   4465],\n",
       "        [  1760,   5437,      7,      4,    293,     60,   3360,   1253,\n",
       "           6528,   1980],\n",
       "        [   208,     10,     17,     52,      9,    364,     44,      8,\n",
       "            304,      4],\n",
       "        [   386,     44,      5,      4,    618,      3,     12,      7,\n",
       "            106,   2087],\n",
       "        [    11,    595,    319,    816,    155,     11,    103,      4,\n",
       "             17,    468],\n",
       "        [     0,     10,     17,     13,    179,     72,   3452,      3,\n",
       "             29,    681],\n",
       "        [  2078,      2,     61,     80,    287,     35,     57,     26,\n",
       "            322,   1258],\n",
       "        [    10,    392,     19,     43,     29,   1497,      4,    710,\n",
       "            112,      3],\n",
       "        [     9,      7,    264,      6,   1549,   6301,      8,    685,\n",
       "              9,      7],\n",
       "        [    10,      7,      4,    123,     70,    853,   1223,     17,\n",
       "              3,     29],\n",
       "        [    10,      7,      2,    333,    673,   4044,     19,      6,\n",
       "           7570,      2],\n",
       "        [    82,     22,     37,    835,     55,     92,    760,    241,\n",
       "             36,      0],\n",
       "        [    66,   2753,   1432,     73,   1466,    301,     27,    236,\n",
       "             57,     25],\n",
       "        [    10,     19,   1683,     69,      5,   3172,    876,   1174,\n",
       "          21748,   5049],\n",
       "        [    74,   1814,      5,  24355,      7,    681,     33,   1050,\n",
       "             17,      2],\n",
       "        [ 23962,   2828,      0,      0,      2,  21064,   2828,      0,\n",
       "            283,   2157],\n",
       "        [    18,     85,     68,     22,    835,      6,      0,      4,\n",
       "           2311,    761],\n",
       "        [    10,     19,      7,      4,   9756,    558,      6,   2269,\n",
       "              8,      2],\n",
       "        [  2331,  12504,      7,      0,   6616,      4,   3203,   4757,\n",
       "             35,    291],\n",
       "        [    74,     11,     89,    117,    113,      6,    870,    518,\n",
       "             10,     13],\n",
       "        [    98,     17,     12,   2098,      2,  11074,   1789,    665,\n",
       "             14,      2],\n",
       "        [    11,   1896,     10,     19,    100,    869,      2,    270,\n",
       "             12,   1580],\n",
       "        [     8,      4,    770,    693,      2,   1864,    130,    739,\n",
       "             98,   4621],\n",
       "        [   143,     21,    243,     11,    368,    113,     31,    128,\n",
       "          11985,      0],\n",
       "        [   484,    209,     20,    810,      6,     25,      4,    110,\n",
       "            250,     52],\n",
       "        [    74,     46,     79,     57,    129,     12,     10,    806,\n",
       "             17,      0],\n",
       "        [    34,    138,     25,    740,     10,     17,   1908,    361,\n",
       "             12,    864],\n",
       "        [  2100,      0,      8,      2,      0,     25,     56,    313,\n",
       "             47,     11],\n",
       "        [    10,    569,    746,     15,    607,   1460,      7,    207,\n",
       "             20,    813],\n",
       "        [    10,    195,     17,      7,     62,      0,      7,     45,\n",
       "             10,      7],\n",
       "        [    10,      7,     33,    312,     17,     14,      4,   2240,\n",
       "             35,   1957],\n",
       "        [    10,     17,     13,    506,    316,    267,      9,     13,\n",
       "             38,     81],\n",
       "        [     2,      0,     12,      0,     20,     10,     19,     23,\n",
       "             74,    604],\n",
       "        [  1133,    353,     19,     15,   3236,      0,    323,   1037,\n",
       "            615,     16],\n",
       "        [    11,     13,    400,      6,    720,     10,     16,      4,\n",
       "           3741,      3],\n",
       "        [    10,    192,    153,     26,      2,    240,     17,     12,\n",
       "             11,     25],\n",
       "        [    10,     17,  20004,     15,     69,     20,    104,   2162,\n",
       "             14,      4],\n",
       "        [   651,    832,   4566,   4055,   7180,   1783,   4107,  22258,\n",
       "              3,     31],\n",
       "        [     0,   1253,     20,      2,    356,   6789,      0,    574,\n",
       "              5,  15147],\n",
       "        [    10,    144,    175,      0,      2,   6061,      5,  13172,\n",
       "             18,      9],\n",
       "        [   280,    713,      4,     60,     48,     13,      4,    174,\n",
       "             32,      2],\n",
       "        [ 17833,      0,  16444,    235,     59,   1136,     39,     33,\n",
       "          14023,   1372],\n",
       "        [   285,    138,    358,   7082,   7755,     12,     39,    611,\n",
       "             14,      4],\n",
       "        [   710,    112,    580,    405,   6742,  19156,    346,     18,\n",
       "            651,   5213],\n",
       "        [   143,     21,      4,    328,      5,   1820,   3142,      8,\n",
       "            185,     11],\n",
       "        [     0,     43,    242,      6,   1848,    407,    168,    675,\n",
       "             17,     36],\n",
       "        [    38,   3705,    309,     13,    400,      6,     26,      4,\n",
       "            195,      3],\n",
       "        [    11,   1799,    492,     10,    378,      4,    711,      5,\n",
       "            104,     11],\n",
       "        [   136,     11,    995,    492,   4775,      0,      4,   1077,\n",
       "            720,     11],\n",
       "        [  3604,   1161,   3340,      2,    238,      5,   1098,   1276,\n",
       "             12,      7],\n",
       "        [   200,    763,      6,     37,     10,     19,     62,      8,\n",
       "            146,      9],\n",
       "        [    10,      7,    210,    756,   2150,    199,     47,    154,\n",
       "             10,     19],\n",
       "        [    14,   8458,     14,     11,     68,     11,   5879,    256,\n",
       "             10,     17],\n",
       "        [    11,    177,      6,  14656,      4,    163,    180,     11,\n",
       "            237,     21],\n",
       "        [    10,    812,      7,     42,     14,     81,     14,     34,\n",
       "            209,     11],\n",
       "        [ 15652,   1741,   9439,    386,    284,      8,     10,     17,\n",
       "            227,     25],\n",
       "        [    11,    468,     11,     61,     25,    523,      6,   1737,\n",
       "             16,      2],\n",
       "        [ 12847,   7636,      3,   3211,   9787,    329,      8,     10,\n",
       "            690,    607]])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 328121), ('and', 161575), ('a', 161309), ('of', 145166), ('to', 134822), ('is', 106799), ('in', 92187), ('it', 76313), ('this', 73186), ('i', 72475), ('that', 69198), ('was', 47988), ('as', 46058), ('with', 43724), ('for', 43701), ('movie', 41826), ('but', 40999), ('film', 37487), ('on', 33340), ('not', 30012)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'this', 'i', 'that', 'was', 'as', 'with', 'for', 'movie', 'but', 'film']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, seq_len, emb_dim, hidden_dim, output_dim, embedding, batch_size, num_layers=1, dropout=0.2, bidirectional=False):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.seq_len = seq_len \n",
    "        self.emb_dim = emb_dim # glove dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = embedding # glove embedding\n",
    "        self.batch_size = batch_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Initalize look-up table and assign weight\n",
    "        self.word_emb = torch.nn.Embedding(25002, emb_dim)\n",
    "        #self.word_emb.weight = torch.nn.Parameter(embedding)\n",
    "        # Layers: one LSTM, one Fully-connected\n",
    "        self.lstm = torch.nn.LSTM(emb_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, batch):\n",
    "        x = self.word_emb(x).permute(1, 0, 2)\n",
    "        h_0 = self._init_state(batch_size=batch)\n",
    "        #print(\"h_0 = \", h_0)\n",
    "        out, (hidden_out, cell_out) = self.lstm(x, h_0)\n",
    "        #print(\"h_t = \", hidden_out)\n",
    "\n",
    "        self.dropout(hidden_out)\n",
    "        y_pred = self.fc(hidden_out[-1])\n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            weight.new(self.num_layers, batch_size, self.hidden_dim).zero_(),\n",
    "            weight.new(self.num_layers, batch_size, self.hidden_dim).zero_()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (word_emb): Embedding(25002, 300)\n",
      "  (lstm): LSTM(300, 256)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "seq_len = 200\n",
    "emb_dim = 300\n",
    "hidden_dim = 256\n",
    "output_dim = 2\n",
    "embedding = word_emb\n",
    "lr = 0.001\n",
    "max_grad_norm = 5\n",
    "\n",
    "\n",
    "model = LSTM(seq_len, emb_dim, hidden_dim, output_dim, embedding, batch_size)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(filter(lambda param: param.requires_grad, model.parameters()), lr=lr ) #,lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def clip_gradient(model, clip_value):\n",
    "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
    "    for p in params:\n",
    "        p.grad.data.clamp_(-clip_value, clip_value)\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "def train(model, data_iter, epoch_size, optimizer):\n",
    "    #init_lstm_weights = copy.deepcopy(model.state_dict())\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "#    for epoch in tqdm(range(epoch_size)):\n",
    "    for epoch in range(epoch_size):\n",
    "        epoch_loss = []\n",
    "        epoch_acc = []\n",
    "        \n",
    "        for i, batch in enumerate(data_iter):\n",
    "            batch_size = len(batch.text[0])\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            #loss = 0\n",
    "            #correct = 0\n",
    "            pred = model(batch.text[0],batch_size)\n",
    "            loss = functional.cross_entropy(pred, batch.label, size_average=False)            \n",
    "            correct = ((torch.max(pred, 1)[1] == batch.label)).sum().numpy()\n",
    "            acc = correct/pred.shape[0]\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_acc.append(acc)\n",
    "     \n",
    "            loss.backward() # calculate the gradient\n",
    "        \n",
    "            #clip_gradient(model, 0.25) # limit the norm\n",
    "            # Clip to the gradient to avoid exploding gradient.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "            optimizer.step() # update param\n",
    "\n",
    "            print(\"------TRAINBatch {}/{}, Batch Loss: {:.4f}, Accuracy: {:.4f}\".format(i+1,len(data_iter), loss, acc))\n",
    "        \n",
    "        total_loss.append((sum(epoch_loss)/len(data_iter)))\n",
    "        total_acc.append((sum(total_acc)/len(data_iter)))\n",
    "        print(\"****** Epoch {} Loss: {}, Epoch {} Acc: {}\".format(epoch, (sum(epoch_loss)/len(data_iter)),\n",
    "                                                                  epoch, (sum(epoch_acc)/len(data_iter))))          \n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "    model.eval()\n",
    "\n",
    "    for i, batch in enumerate(val_iter):\n",
    "        batch_size = len(batch.text[0])\n",
    "        pred = model(batch.text[0],batch_size)\n",
    "        loss = functional.cross_entropy(pred, batch.label, size_average=False)            \n",
    "        correct = ((torch.max(pred, 1)[1] == batch.label)).sum().numpy()\n",
    "        acc = correct/pred.shape[0]\n",
    "        total_loss.append(loss.item())\n",
    "        total_acc.append(acc)\n",
    "        print(\"++++++EVAL Batch {}/{}, Batch Loss: {:.4f}, Accuracy: {:.4f}\".format(i+1,len(val_iter), loss, acc))\n",
    "    print(\"Average EVAL Loss: \", (sum(total_loss) / len(val_iter))) \n",
    "    print(\"Average EVAL Acc: \", (sum(total_acc) / len(val_iter))) \n",
    "    return avg_total_loss, total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperpram_tune(hidden_dim_lst = [64,128,256], lr_lst = [0.1,0.01,0.001], max_grad_norm_lst = [3,4,5], epoch_lst = [10,20,30,40,50]):\n",
    "    best_valid_loss = 0\n",
    "    best_model = model\n",
    "    for dim in hidden_dim_lst:\n",
    "        for rate in lr_lst:\n",
    "            for norm in max_grad_norm_lst:\n",
    "                for epoch in epoch_lst:\n",
    "                    lr = rate\n",
    "                    max_grad_norm = norm\n",
    "                    print(\"&&&& hidden_dim {}, lr {}, max_grad_norm {}, epoch {}\".format(dim,rate,norm,epoch))\n",
    "                    this_model = LSTM(seq_len, emb_dim, dim, output_dim, embedding, batch_size)\n",
    "                    _, _ = train(model, train_data, epoch , optimizer)  \n",
    "                    avg_valid_loss, _, _ = evaluate(model, valid_data)\n",
    "                    if avg_valid_loss > best_valid_loss:\n",
    "                        best_model = this_model\n",
    "    return best_model\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loss, train_acc = train(model, train_data, 20, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_total_loss, valid_total_acc = evaluate(model, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Batch 1/274, Batch Loss: 44.4360, Accuracy: 0.4531\n",
      "------Batch 2/274, Batch Loss: 53.1576, Accuracy: 0.5938\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-553-f978ff3161d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperpram_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-550-d1e80c507c57>\u001b[0m in \u001b[0;36mhyperpram_tune\u001b[0;34m(hidden_dim_lst, lr_lst, max_grad_norm_lst, epoch_lst)\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mmax_grad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mthis_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                     \u001b[0mavg_valid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mavg_valid_loss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_valid_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-536-8dcfdcd7748e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_iter, epoch_size, optimizer)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mepoch_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#clip_gradient(model, 0.25) # limit the norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = hyperpram_tune()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TRY\n",
    "a) learning rates\n",
    "b) different numbers of hidden layers\n",
    "c) different dim of hidden layers\n",
    "d) try gradient clipping instead of changing the learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight updates\n",
    "epoch batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
