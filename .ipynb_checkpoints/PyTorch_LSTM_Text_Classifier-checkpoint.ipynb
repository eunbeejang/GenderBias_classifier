{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Text Classifier\n",
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eunbeejang/anaconda3\n",
      "/usr/local/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.prefix)\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe, Vectors\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "from tqdm import tqdm # progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    tokenize = lambda x: lemma.lemmatize(re.sub(r'<.*?>|[^\\w\\s]|\\d+', '', x)).split()\n",
    "    \n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True,\n",
    "                      fix_length=200, include_lengths=True, batch_first=True, dtype=torch.long)\n",
    "    LABEL = data.LabelField(dtype=torch.float, sequential=False)\n",
    "\n",
    "    train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "    \n",
    "    TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300)) # Glove Embedding\n",
    "    LABEL.build_vocab(train)\n",
    "    word_emb = TEXT.vocab.vectors\n",
    "    \n",
    "    train, valid = train.split()\n",
    "    train_data, valid_data, test_data = data.BucketIterator.splits((train, valid, test),\n",
    "                                                                   batch_size=32, repeat=False, shuffle=True)\n",
    "\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    print (\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n",
    "    print (\"Vector size of Text Vocabulary: \", TEXT.vocab.vectors.size())\n",
    "    print (\"Label Length: \" + str(len(LABEL.vocab)))\n",
    "    print (\"\\nSize of train set: {} \\nSize of validation set: {} \\nSize of test set: {}\".format(len(train_data.dataset), len(valid_data.dataset), len(test_data.dataset)))\n",
    "    print(LABEL.vocab.freqs.most_common(2))\n",
    "\n",
    "    return TEXT, word_emb, train_data, valid_data, test_data, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pos', 12500), ('neg', 12500)]\n",
      "Length of Text Vocabulary: 138163\n",
      "Vector size of Text Vocabulary:  torch.Size([138163, 300])\n",
      "Label Length: 2\n",
      "\n",
      "Size of train set: 17500 \n",
      "Size of validation set: 7500 \n",
      "Size of test set: 25000\n"
     ]
    }
   ],
   "source": [
    "TEXT, word_emb, train_data, valid_data, test_data, vocab_size = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a in train_data:\n",
    "    b = a.text\n",
    "    break\n",
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0000e+00,  2.1324e+04,  8.4260e+03,  5.6230e+03,  4.2660e+03,\n",
       "          4.4170e+03,  6.1800e+03,  3.0760e+03,  5.3300e+02,  3.0000e+00],\n",
       "        [ 8.6690e+03,  1.1911e+04,  7.0000e+00,  2.8000e+01,  5.0000e+00,\n",
       "          1.4200e+02,  1.2160e+03,  9.3000e+01,  1.2000e+01,  2.8880e+03],\n",
       "        [ 1.0000e+01,  7.0000e+00,  4.0000e+00,  4.9000e+01,  1.9000e+01,\n",
       "          1.6000e+01,  5.0000e+00,  2.0000e+00,  5.7780e+03,  1.1000e+01],\n",
       "        [ 1.0000e+01,  7.0000e+00,  2.8000e+01,  5.0000e+00,  1.4200e+02,\n",
       "          3.8100e+02,  5.3111e+04,  6.2050e+03,  1.2000e+01,  4.0100e+02],\n",
       "        [ 2.3400e+02,  1.0000e+01,  1.7000e+01,  1.3000e+01,  4.4700e+02,\n",
       "          2.0000e+01,  4.0000e+00,  2.7800e+02,  6.3000e+01,  5.0000e+00],\n",
       "        [ 1.1000e+01,  6.6000e+01,  1.0900e+02,  5.3600e+02,  5.0000e+00,\n",
       "          6.5100e+02,  2.2350e+03,  1.4872e+04,  1.5500e+02,  2.0610e+03],\n",
       "        [ 4.1000e+01,  1.1229e+05,  1.0000e+01,  1.1000e+01,  8.9000e+01,\n",
       "          1.7700e+02,  6.0000e+00,  4.1900e+02,  9.9000e+01,  7.2000e+01],\n",
       "        [ 4.1000e+01,  4.0000e+00,  9.7900e+02,  1.6500e+02,  1.7000e+01,\n",
       "          8.6000e+01,  1.1498e+04,  4.9600e+02,  2.0100e+02,  2.4000e+01],\n",
       "        [ 1.4250e+03,  1.1000e+01,  6.2000e+01,  4.0200e+02,  1.0000e+01,\n",
       "          1.7000e+01,  1.0080e+03,  2.9260e+03,  4.5640e+03,  7.0000e+00],\n",
       "        [ 9.0000e+00,  6.2000e+01,  1.3000e+01,  1.2000e+01,  8.1000e+01,\n",
       "          2.0000e+01,  4.0000e+00,  2.9350e+03,  1.5000e+01,  2.0000e+00],\n",
       "        [ 6.4200e+02,  1.2140e+03,  3.6000e+01,  2.0000e+00,  7.4140e+03,\n",
       "          9.5300e+02,  2.6000e+03,  2.0000e+00,  5.7910e+03,  1.2910e+03],\n",
       "        [ 1.1000e+01,  2.0510e+03,  5.9700e+02,  1.0000e+01,  4.2800e+02,\n",
       "          1.4700e+02,  5.8500e+02,  1.3600e+02,  1.2600e+03,  4.2700e+03],\n",
       "        [ 2.0000e+00,  1.3102e+04,  5.0000e+00,  1.6694e+04,  7.0000e+00,\n",
       "          4.0000e+00,  6.1670e+03,  9.5100e+02,  5.0000e+00,  4.0000e+00],\n",
       "        [ 1.1000e+01,  2.5000e+01,  1.0700e+02,  1.5790e+03,  1.6000e+02,\n",
       "          4.2800e+02,  2.1100e+02,  3.0000e+00,  7.0000e+00,  2.3600e+02],\n",
       "        [ 2.0000e+00,  7.7300e+02,  1.9000e+01,  1.0498e+04,  7.1740e+03,\n",
       "          4.5418e+04,  8.3200e+02,  9.7600e+02,  4.9371e+04,  5.2600e+02],\n",
       "        [ 1.4000e+01,  2.3300e+02,  1.4000e+01,  1.1000e+01,  1.1700e+02,\n",
       "          1.0000e+01,  1.1900e+02,  1.3000e+01,  1.0900e+02,  2.3500e+03],\n",
       "        [ 1.4600e+02,  1.9000e+01,  1.1000e+01,  1.3000e+01,  8.0000e+00,\n",
       "          5.1000e+01,  6.9400e+02,  1.2640e+03,  3.0000e+00,  8.3000e+01],\n",
       "        [ 1.0000e+01,  7.2000e+02,  7.0000e+00,  6.3700e+02,  3.1000e+01,\n",
       "          1.3010e+03,  4.5000e+01,  2.2000e+01,  1.2720e+03,  2.0000e+01],\n",
       "        [ 1.1000e+01,  4.6800e+02,  1.2000e+01,  1.4211e+04,  2.6800e+02,\n",
       "          1.7500e+02,  1.4000e+01,  6.1540e+03,  1.4000e+01,  8.7000e+01],\n",
       "        [ 1.1000e+01,  4.1000e+01,  2.8100e+02,  1.0000e+01,  1.6000e+01,\n",
       "          2.0000e+00,  8.6000e+01,  6.0000e+01,  8.0000e+00,  4.0000e+00],\n",
       "        [ 7.9400e+02,  3.6600e+02,  1.1070e+03,  7.3600e+02,  7.5300e+02,\n",
       "          1.3310e+03,  1.7800e+02,  5.8000e+01,  1.3040e+03,  5.0000e+00],\n",
       "        [ 5.9500e+02,  5.2000e+01,  4.0000e+00,  1.7000e+01,  4.7820e+03,\n",
       "          4.0000e+00,  2.2680e+03,  5.0000e+00,  2.8000e+01,  9.0000e+00],\n",
       "        [ 1.1000e+01,  8.9000e+01,  3.6800e+02,  2.1000e+01,  1.0600e+02,\n",
       "          4.0000e+00,  3.8240e+03,  1.1000e+01,  2.3700e+02,  2.1000e+01],\n",
       "        [ 1.0827e+04,  9.4150e+03,  3.8600e+02,  1.4000e+01,  7.0500e+02,\n",
       "          3.0179e+04,  1.4320e+03,  3.3000e+01,  3.2027e+04,  8.2260e+03],\n",
       "        [ 4.0000e+00,  4.5900e+03,  5.2210e+03,  7.1000e+02,  1.9000e+01,\n",
       "          2.7500e+02,  8.0000e+00,  4.0000e+00,  8.7000e+01,  3.9050e+03],\n",
       "        [ 1.0000e+01,  7.0000e+00,  4.0000e+00,  1.9000e+01,  1.1300e+02,\n",
       "          2.0000e+00,  1.4900e+02,  2.3000e+01,  3.1000e+01,  4.6000e+02],\n",
       "        [ 1.4000e+01,  8.0000e+01,  1.8180e+03,  2.5000e+01,  3.0880e+03,\n",
       "          1.0000e+01,  7.0000e+00,  3.3000e+01,  1.3505e+04,  6.8160e+03],\n",
       "        [ 3.0000e+01,  8.6000e+01,  1.1000e+01,  1.5100e+02,  1.0200e+02,\n",
       "          1.2000e+01,  9.9800e+02,  6.4730e+03,  9.5000e+01,  6.2000e+01],\n",
       "        [ 1.1000e+01,  2.5000e+01,  7.3000e+01,  2.7700e+02,  1.6000e+01,\n",
       "          1.0000e+01,  1.9000e+01,  1.6000e+01,  1.9940e+03,  7.8000e+01],\n",
       "        [ 1.0000e+01,  5.7000e+01,  2.6000e+01,  2.0000e+00,  2.4000e+02,\n",
       "          1.9000e+01,  4.4500e+02,  1.2100e+02,  1.0700e+02,  9.0050e+03],\n",
       "        [ 1.2494e+05,  2.1000e+03,  1.4670e+04,  7.0000e+00,  4.0000e+00,\n",
       "          5.1000e+01,  9.2700e+02,  1.9000e+01,  5.2600e+02,  3.2000e+01],\n",
       "        [ 6.2770e+03,  8.4170e+03,  2.8300e+02,  4.0000e+00,  7.7200e+02,\n",
       "          2.1530e+03,  2.8700e+02,  3.5000e+01,  4.3000e+01,  6.8620e+03]])"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who'"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([138163, 300])"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 328121), ('and', 161575), ('a', 161309), ('of', 145166), ('to', 134822), ('is', 106799), ('in', 92187), ('it', 76313), ('this', 73186), ('i', 72475), ('that', 69198), ('was', 47988), ('as', 46058), ('with', 43724), ('for', 43701), ('movie', 41826), ('but', 40999), ('film', 37487), ('on', 33340), ('not', 30012)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'this', 'i', 'that', 'was', 'as', 'with', 'for', 'movie', 'but', 'film']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, seq_len, emb_dim, hidden_dim, output_dim, embedding, batch_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.seq_len = seq_len # vocabulary dim\n",
    "        self.emb_dim = emb_dim # glove dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = embedding # glove embedding\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Initalize look-up table\n",
    "        self.word_emb = torch.nn.Embedding(seq_len, emb_dim, padding_idx=1)\n",
    "        # connect look-up table to glove embedding\n",
    "        self.word_emb.weight = torch.nn.Parameter(embedding, requires_grad=False)\n",
    "        \n",
    "        # Layers: one LSTM, one Fully-connected\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim)\n",
    "        #self.lstm = nn.LSTM(seg_len, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "        #print(\"testing\")\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x, batch_size):\n",
    "        \n",
    "        # input_emb (num_seq, batch_size, emb_dim)\n",
    "        #print(\"X: \", x.shape)\n",
    "        emb_input = self.word_emb(x).permute(1, 0, 2)  \n",
    "        #print(\"emb_input: \", emb_input.shape)\n",
    "        hidden_state = Variable(torch.zeros(1, batch_size, self.hidden_dim))\n",
    "        cell_state = Variable(torch.zeros(1, batch_size, self.hidden_dim))\n",
    "        #print(\"hidden_state: \", hidden_state.shape)\n",
    "        out, (hidden_out, cell_out) = self.lstm(emb_input, (hidden_state, cell_state))\n",
    "        #print(\"out: \", out.shape)\n",
    "        #print(\"hidden_out: \", hidden_out.shape)\n",
    "        y_pred = (self.out(hidden_out[-1]))\n",
    "        #print(\"y_pred: \", y_pred)\n",
    "        return y_pred\n",
    "        \"\"\"\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        outputs, (hidden, cell) = self.LSTM(embedded)\n",
    "        return outputs, hidden\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 200 #vocab_size\n",
    "emb_dim = 300\n",
    "hidden_dim = 256\n",
    "output_dim = 2\n",
    "embedding = word_emb\n",
    "batch_size = 32\n",
    "\n",
    "model = LSTM(seq_len, emb_dim, hidden_dim, output_dim, embedding, batch_size)\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index=TEXT.vocab.stoi['<pad>'])\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda param: param.requires_grad, model.parameters()),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x1a2c8617d8>"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_iter, epoch_size, criterion, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "    #epoch = 0\n",
    "    #for epoch in tqdm(range(epoch_size)):\n",
    "    for epoch in range(epoch_size):\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            #print(\"\\n batch {}: \".format(i))\n",
    "            batch_size = len(batch.text[0])\n",
    "            pred = model(batch.text[0], batch_size)\n",
    "            pred = torch.max(pred, 1)[1]\n",
    "            #print(\"\\tprediction: \", pred)\n",
    "            #print(\"\\ttarget: \", batch.label)\n",
    "            loss = Variable(criterion(pred.float(), batch.label.float()), requires_grad = True)\n",
    "            correct = ((pred.float() == batch.label).sum()).numpy()\n",
    "            #correct = (pred == batch.label.type(torch.LongTensor)).sum().data\n",
    "            #print(\"Correct: \", correct)\n",
    "            #print(correct)\n",
    "            acc = correct/pred.shape[0]\n",
    "            #print(acc)\n",
    "            optimizer.zero_grad()      \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            #print(\"This Batch {}/{}, Loss: {:.4f}, Accuracy: {:.4f}\".format(epoch+1,epoch_size, loss, acc))\n",
    "        print(\"------epoch {}/{}, Loss: {:.4f}, Accuracy: {:.4f}\".format(epoch+1,epoch_size, loss, acc))\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------epoch 1/10, Loss: 18.4207, Accuracy: 0.3333\n",
      "------epoch 2/10, Loss: 18.4207, Accuracy: 0.3333\n",
      "------epoch 3/10, Loss: 18.4207, Accuracy: 0.3333\n",
      "------epoch 4/10, Loss: 18.4207, Accuracy: 0.3333\n",
      "------epoch 5/10, Loss: 18.4207, Accuracy: 0.3333\n",
      "------epoch 6/10, Loss: 18.4207, Accuracy: 0.3333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-822-91980274eb11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-821-64bc02540d44>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_iter, epoch_size, criterion, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m#print(\"\\n batch {}: \".format(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#print(\"\\tprediction: \", pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-753-04e6e7fc88d0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#print(\"hidden_state: \", hidden_state.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m#print(\"out: \", out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print(\"hidden_out: \", hidden_out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mingate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, valid_data, 10, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
