# Gender Bias Classifier

> *This repository contains a LSTM based text classifier for gender bias detection. This is part of MILA's BiaslyAI project, which aims to build a text-based dataset to help mitigate gender bias issue present in natural language. Due to privacy reasons, data cannot be released to the public at the moment.*

Gender bias refers to the automatic assumptions that we as humans make based on gender. These assumptions are often based on societal standards and the influences of culture and the media. BiaslyAI is investigating the ways that implicit gender bias materializes in text. For example, gender bias may emerge as someone assuming the gender of a gender neutral noun based on the type of profession or other parts of the sentence as in *[A programmer] must always carry [his] laptop.*; or referring to a mixed group of people as “guys.”

Most work related to gender bias within the machine learning community is focused on debiasing existing models such as word embeddings, coreference resolution and captioning. We propose to build a dataset from which a model can be trained to detect gender bias in text. 

A model trained on a robust gender bias dataset could directly address the negative preconceived ideas people have about gender and guide human judgments by recognizing their gender biases. This could then initiate reflections on gender-sensitive topics and empower the movement of fairness and equity for all genders.

As a first step, we are following our proposed taxonomy and looking for one subtype of bias at a time. We believe in an interdisciplinary approach to tackling gender bias in text and are working closely with experts in sociolinguistics, history and nlp. 




https://www.biaslyai.com

https://medium.com/biaslyai
